{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Appliances Energy Prediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPX1STgKe61bjmhLo1Lj+3m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Umesh1307/Appliances-Energy-Prediction-Regression-Analysis-Almabetter-Capstone-Project-No.-2/blob/main/Appliances_Energy_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## The data set is at 10 min for about 4.5 months. The house temperature and humidity conditions were monitored with a ZigBee wireless sensor network. Each wireless node transmitted the temperature and humidity conditions around 3.3 min. Then, the wireless data was averaged for 10 minutes periods. The energy data was logged every 10 minutes with m-bus energy meters. Weather from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis (rp5.ru) and merged together with the experimental data sets using the date and time column. Two random variables have been included in the data set for testing the regression models and to filter out non-predictive attributes(parameters).\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### 1. date: year-month-day hour:minute:second\n",
        "### 2. T1: Temperature in kitchen area, in Celsius\n",
        "### 3. RH_1: Humidity in kitchen area, in %\n",
        "### 4. T2: Temperature in living room area, in Celsius\n",
        "### 5. RH_2: Humidity in living room area, in %\n",
        "### 6. T3: Temperature in laundry room area\n",
        "### 7. RH_3: Humidity in laundry room area, in %\n",
        "### 8. T4: Temperature in office room, in Celsius\n",
        "### 9. RH_4: Humidity in office room, in %\n",
        "### 10. T5: Temperature in bathroom, in Celsius\n",
        "### 11. vRH_5: Humidity in bathroom, in %\n",
        "### 12. T6: Temperature outside the building (north side), in Celsius\n",
        "### 13. RH_6: Humidity outside the building (north side), in %\n",
        "### 14. T7: Temperature in ironing room, in Celsius\n",
        "### 15. RH_7: Humidity in ironing room, in %\n",
        "### 16. T8: Temperature in teenager room 2, in Celsius\n",
        "### 17. RH_8: Humidity in teenager room 2, in %\n",
        "### 18. T9: Temperature in parentsâ€™ room, in Celsius\n",
        "### 19. RH_9: Humidity in parentsâ€™ room, in %\n",
        "### 20. T_out: Temperature outside (from Chievres weather station), in Celsius\n",
        "### 21. Pressure: (from Chievres weather station), in mm Hg\n",
        "### 22. RH_out: Humidity outside (from Chievres weather station), in %\n",
        "### 23. Wind speed: (from Chievres weather station), in m/s\n",
        "### 24. Visibility: (from Chievres weather station), in km\n",
        "### 25. T_dewpoint: (from Chievres weather station), Ã‚Â°C\n",
        "### 26. rv1: Random variable 1, non-dimensional\n",
        "### 27. rv2: Random variable 2, non-dimensional\n",
        "### 28. Lights: energy use of light fixtures in the house in Wh\n",
        "### 29. Appliances: energy use in Wh (Target Variable)\n",
        "\n",
        "## Where indicated, hourly data (then interpolated) from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis,rp5.ru. Permission was obtained from Reliable Prognosis for the distribution of the 4.5 months of weather data.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WsUW8XM_hLNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "##ðŸ˜‡ Before Delving deep straight into the coding part, let's understand the problem statement together ðŸ˜‡\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Energy is the ability to do work. Scientists define energy as the ability to do work. Modern civilization is possible because people have learned how to change energy from one form to another and then use it to do work. People use energy to walk and bicycle, to move cars along roads and boats through water, to cook food on stoves, to make ice in freezers, to light our homes and offices, to manufacture products, and to send astronauts into space.\n",
        "\n",
        "### There are many different forms of energy, including:\n",
        "\n",
        "### Heat\n",
        "\n",
        "### Light\n",
        "\n",
        "### Motion\n",
        "\n",
        "### Electrical\n",
        "\n",
        "### Chemical\n",
        "\n",
        "### Gravitational\n",
        "\n",
        "## ðŸ˜‡ curious to know about energy more refere this [link text](https://www.eia.gov/energyexplained/what-is-energy/)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Definition of Attributes:\n",
        "\n",
        "---\n",
        "* ## **Relative Humidity:**\n",
        "\n",
        "\n",
        "\n",
        "### **Relative Humidity is the amount of water vapour present in air expressed in the percentage of the amount needed for saturation at the same temperature. It the amount of water vapour is in the air. It is actually the ratio of the amount of water vapour the air can hold that the temperature.**\n",
        "\n",
        "\n",
        "\n",
        "* ## **Dew Point Temperature:**\n",
        "\n",
        "\n",
        "### **The dew point temperature of compressed air is the temperature at which water begins to condense out of the air into a liquid form.**\n",
        "\n",
        "\n",
        "\n",
        "* ## **Temperature**:\n",
        "\n",
        "### **It denotes the degree of hotness and coldness of a body.**\n",
        "\n",
        "\n",
        "\n",
        "* ## **Wind Speed**:\n",
        "\n",
        "### **It the speed at which wind flows, it plays vital role for cooling of building, condensation of air.**\n",
        "\n",
        "\n",
        "\n",
        "* ## **Visibility**:\n",
        "\n",
        "### **The quality or state of being visible. The degree of clearness (as of the atmosphere or ocean) specifically the greatest distance through the atmosphere toward the horizon at which prominent objects can be identified with the naked eye capability of being readily noticed.**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Objective of Project:\n",
        "---\n",
        "### The increasing trend in energy consumption is becoming cause of concern for the entire world, as the energy consumption is increasing year after year so is the carbon and greenhouse gas emission, the majority portion of the electricity generated is consumed by industrial sector but a considerable amount is also consumed by residential sector. It is important to study the energy consuming behaviour in the residential sector and predict the energy consumption by home appliances as it consume maximum amount of energy in the residence. This project focuses on predicting the energy consumption of home appliances based on humidity and temperature.\n",
        "\n",
        "---\n",
        "\n",
        "# What we can do?\n",
        "\n",
        "---\n",
        "### Energy prediction of appliances requires identifying and predicting individual appliance energy consumption when combined in a closed chain environment. This experiment aims to provide insight into reducing energy consumption by identifying trends and appliances involved.\n",
        "### Power prediction has been a major concern in power system for effective energy utilization to reduce demand.\n",
        "\n",
        "# Tentative Roadmap to Follow:\n",
        "\n",
        "---\n",
        "\n",
        "* ### Loading the dataset.\n",
        "\n",
        "* ### cleaning and transforming of features (Null value treatment, Data type consistency check).\n",
        "* ### Descriptive statistical analysis.\n",
        "* ### Skewness and outlier (anomalies) detection analysis.\n",
        "* ### Feature engineering (standardizing, normalizing, multicolinearity assumption check, linearity between independent and dependent variable check).\n",
        "* ### Exploratory data analysis(understanding the patteren and behaviour of data. EDA involves generating summary statistics for numerical data in the dataset and creating various graphical representations to understand the data better).\n",
        "* ### Understanding the feature importance (PCA can be handy for feature selection, lasso regression can be a another option).\n",
        "* ### Model Selection.\n",
        "* ### Model Training.\n",
        "* ### Model Evaluation.\n",
        "* ### Conclusion.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U_td3b31hLQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***STEP 1: LOADING THE DATASET***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gQS6TVr9NhAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get started with very first step loading the wapon's(libraries):\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.decomposition import PCA, LatentDirichletAllocation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn import neighbors\n",
        "from sklearn.svm import SVR\n",
        "import time\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow.keras import Sequential, layers, Input\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M9vqjY5P8JdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting the drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vvzPF0iR9Sao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the directorial path for the data set:\n",
        "dir_path=\"/content/drive/MyDrive/Almabetter Project/Capstone - Projects/Module 4 Supervised ML Regression/Appliances Energy Prediction\""
      ],
      "metadata": {
        "id": "QuSWQ7c682g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset:\n",
        "energy_df=pd.read_csv(dir_path+\"/data_application_energy.csv\")"
      ],
      "metadata": {
        "id": "ruL0QLoO9tAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the head of the dataset, traditional way yet useful\n",
        "energy_df.head()"
      ],
      "metadata": {
        "id": "eKfqpe0--ZKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's use the colab data table feature to visualize explictly! This feature was new one for me :)\n",
        "from google.colab.data_table import DataTable\n",
        "DataTable(energy_df)"
      ],
      "metadata": {
        "id": "6NPc9hTbFnXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A few interesting features of the data table display:ðŸ˜‡\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "* ### Clicking the Filter button in the upper right allows you to search for terms or values in any particular column.\n",
        "* ### Clicking on any column title lets you sort the results according to that column's value.\n",
        "* ### The table displays only a subset of the data at a time. You can navigate through pages of data using the controls on the lower right.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Fgw4BzXFJ0EO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the tail of the dataset:)\n",
        "energy_df.tail(3)\n"
      ],
      "metadata": {
        "id": "WC8lgMqxA-Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the shape of the dataset:)\n",
        "print(f\"The Shape of dataset is {energy_df.shape} There are {energy_df.shape[0]} rows and {energy_df.shape[1]} columns\")"
      ],
      "metadata": {
        "id": "T7nx5TEPJQld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's have a look at the data type of the features.\n",
        "energy_df.info()"
      ],
      "metadata": {
        "id": "bGKFDRSpLXrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Observations:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* ### **Number of entries** : **19735**\n",
        "* ### **Number of features : 27 ( 2 Random Variables excluded )**\n",
        "\n",
        "* ### **Target Variable : Appliances**\n",
        "\n",
        "* ### **There are no categorical feature in the data. There are two 'int' features which might be categorical. We will check it later in the notebook**.\n",
        "\n",
        "* ### **There are no information about the features rv1, rv2 and what it denotes. We will keep it or discard it based on its relationship with the target variable.**\n",
        "\n",
        "* ### **There are in total 29 variables out of which 28 are independent variables and 1 is dependent which is our target variable.**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QdqCU8PBMO35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rechecking for the null values if any\n",
        "energy_df.isnull().sum()"
      ],
      "metadata": {
        "id": "6S0sL8frLrub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## ***DESCRIPTIVE STATISTICAL ANALYSIS***\n",
        "\n",
        "---\n",
        "### Here we will be using pandas describe method to have an intution about the basic behaviour of data, furthermore we will use pandas profilling to have a more understanding of the data.\n"
      ],
      "metadata": {
        "id": "Em870ctyOIXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's use pandas describe method\n",
        "energy_df.describe()"
      ],
      "metadata": {
        "id": "qux_Z-2ONXi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **It is puzzling the mind, making unable to draw inference by looking at whole dataset description. What we can do is we can create two other dataframes containing all the temperatures in one dataframe from dataset and, relative humidity in other.**##\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wSZm_xW1d6wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dictionary of all the tempreatures from the dataset naming it as temp_dict\n",
        "temp_dict = {\n",
        "    'T1' : 'temp_kitchen', 'T2' : 'temp_living', 'T3' : 'temp_laundry', \n",
        "    'T4' : 'temp_office', 'T5' : 'temp_bath', 'T6' : 'temp_outside',\n",
        "    'T7' : 'temp_iron', 'T8' : 'temp_teen', 'T9' : 'temp_parents', 'T_out' : 'temp_station'\n",
        "}"
      ],
      "metadata": {
        "id": "iSFsTLqCPE2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the attributes\n",
        "energy_df = energy_df.rename(columns=temp_dict)"
      ],
      "metadata": {
        "id": "mZ9ZJAlSfc72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dictionary of all the relative humidity attributes\n",
        "humid_dict = {\n",
        "    'RH_1' : 'humid_kitchen', 'RH_2' : 'humid_living', 'RH_3' : 'humid_laundry', \n",
        "    'RH_4' : 'humid_office', 'RH_5' : 'humid_bath', 'RH_6' : 'humid_outside',\n",
        "    'RH_7' : 'humid_iron', 'RH_8' : 'humid_teen', 'RH_9' : 'humid_parents', 'RH_out' : 'humid_station'\n",
        "}"
      ],
      "metadata": {
        "id": "q--v35ICgD5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the attributes\n",
        "energy_df = energy_df.rename(columns=humid_dict)"
      ],
      "metadata": {
        "id": "IfK4tV-pgj6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's have look at the description of temp_dic:)\n",
        "from google.colab import data_table                           # Importing the datatable extension of google colab.\n",
        "data_table._DEFAULT_FORMATTERS[float] = lambda x: f\"{x:.2f}\"  # Formatting the float values of the attributes.\n",
        "energy_df[temp_dict.values()].describe()                      # Using the describe method of pandas. "
      ],
      "metadata": {
        "id": "_wzI-u-sg_TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **OBSERVATIONS :**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "* ### **Average outside temperature over a period of 4.5 months is around 7.5 degrees. It ranges from -6 to 28 degrees.**\n",
        "* ### **While average temperature inside the building has been around 20 degrees for all the rooms. It ranges from 14 - 30 degrees.**\n",
        "* ### **Which implies, Warming appliances have been used to keep the insides of the building warm.There must be some sort of direct correlation between temperature and consumption of energy inside house.**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0D7U8T2Rn8Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's draw some conclusions from humidity dict:\n",
        "from google.colab import data_table                             # Importing the datatable extension of google colab.\n",
        "data_table._DEFAULT_FORMATTERS[float] = lambda x: f\"{x:.2f}\"    # Formatting the float values of the attributes.\n",
        "energy_df[humid_dict.values()].describe()                       # Using the describe method of pandas.\n"
      ],
      "metadata": {
        "id": "p59RGCX2n2wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **Observations:**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* ### **Average humidity outside the building has been higher than the average humidity inside.**\n",
        "* ### **Average humidity at the weather station is significantly higher compared to outside humidity near the building.**\n",
        "\n",
        "* ### **Average humidity in the bathroom is significantly higher compared to other rooms due to obvious reasons.**\n",
        "\n",
        "* ### **Kids and parent room show a comparatively higher average humidity as well signifying the fact that, inhabitants of this building spend most of their time in these buildings.**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5vK3vILjoyt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seggregate the columns based on its category.\n",
        "temp_cols =['temp_kitchen', 'temp_living', 'temp_laundry', \n",
        "    'temp_office', 'temp_bath', 'temp_outside',\n",
        "    'temp_iron', 'temp_teen',  'temp_parents', 'temp_station']\n",
        "\n",
        "humid_cols =['humid_kitchen','humid_living',  'humid_laundry', \n",
        "    'humid_office', 'humid_bath',  'humid_outside',\n",
        "    'humid_iron', 'humid_teen', 'humid_parents', 'humid_station']\n",
        "\n",
        "weather_cols =[\"Tdewpoint\",\"Press_mm_hg\",\"Windspeed\",\"Visibility\"]\n",
        "\n",
        "light_cols = [\"lights\"]\n",
        "\n",
        "random_cols = [\"rv1\", \"rv2\"]\n",
        "\n",
        "date_time_cols = ['month', 'weekday', 'hour', 'week']\n",
        "\n",
        "target = [\"Appliances\"]"
      ],
      "metadata": {
        "id": "AweYfyF1oxc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features=energy_df[temp_cols+ humid_cols+ weather_cols+ light_cols+ random_cols+ target]"
      ],
      "metadata": {
        "id": "vr1oLO6q3TL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numeric_features[1:-1]:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = energy_df[col]\n",
        "    label = energy_df['Appliances']\n",
        "    correlation = feature.corr(label)\n",
        "    plt.scatter(x=feature, y=label)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Appliances')\n",
        "    ax.set_title('Appliances vs ' + col + '- correlation: ' + str(correlation))\n",
        "    z = np.polyfit(energy_df[col], energy_df['Appliances'], 1)\n",
        "    y_hat = np.poly1d(z)(energy_df[col])\n",
        "\n",
        "    plt.plot(energy_df[col], y_hat, \"r--\", lw=1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q9pXGKaF3L6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the distribution of the data using histogram\n",
        "energy_df[temp_cols+ humid_cols+ weather_cols+ light_cols+ random_cols+ target].hist(bins=50, figsize=(20,25))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C6JLk5Z32MzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using histogram we are able to understand the distribution of data, however there is a useful plot called normal probability plot which is used to check the normality or the normal distribution of the data. below we will use probability plot, and see how distribution deviates from the theoretical values of the distribution.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3cyZsvlnlAW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's use normal probability plot for checking the normal distribution of data\n",
        "for col in energy_df[temp_cols+ humid_cols+ weather_cols+ light_cols+ random_cols+ target].columns:\n",
        "    stats.probplot(energy_df[col], dist='norm', plot=plt, fit=True)\n",
        "    plt.title(col)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XgA8SztBj-qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **Observations**:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## **Features Near to Normal Distribution:**\n",
        "\n",
        "\n",
        "\n",
        "### pressure, humid_iron, humid_teen, humid_parents , temp_station, humid_living,humid_laundry,humid_office,humid_bath, humid_kitchen, temp_outside, temp_iron, temp_teen, temp_kitchen, temp_living.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **skewed features:**\n",
        "\n",
        "### Appliances, visibility, windspeed, humid_station, t dewpoint, temp_parents, temp_laundry, temp_office, temp_bath.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **Randomly Distributed Features :**\n",
        "\n",
        " ### rv1, rv2, humid_outside\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### Note: Our target variable is skewed. We will apply some transofrmation on it to bring it closer to normal distribution.some transformations that can be done to make the feature normal are:\n",
        "\n",
        "1. Log\n",
        "2. Exponential\n",
        "3. square root\n",
        "4. box-cox\n",
        "5. reciprocal\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9q22i6X06Dna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_var_original = energy_df[['Appliances']].copy()\n",
        "# normality check\n",
        "def normality(data,feature):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    sns.kdeplot(data[feature])\n",
        "    plt.subplot(1,2,2)\n",
        "    stats.probplot(data[feature],plot=plt)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XFlAPqN24Yr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the normality of the target variable using kde(kernal density estimation line) and normal probability graph\n",
        "normality(target_var_original,'Appliances')"
      ],
      "metadata": {
        "id": "Gg3g8XuTE-EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing the log transformation on target variable\n",
        "target_var_original['log_transform']=np.log(target_var_original['Appliances'])\n",
        "normality(target_var_original,'log_transform')\n",
        "# Performing the reciprocal transformation on target variable\n",
        "target_var_original['reciprocal_transform']=1/target_var_original.Appliances\n",
        "normality(target_var_original,'reciprocal_transform')\n",
        "# Performing the square root transformation on target variable\n",
        "target_var_original['sqroot_transform']= np.sqrt(target_var_original.Appliances)\n",
        "normality(target_var_original,'sqroot_transform')\n",
        "# Performing the boxcox transformation\n",
        "target_var_original['boxcox_transform'], parameters= stats.boxcox(target_var_original['Appliances'])\n",
        "normality(target_var_original,'boxcox_transform')"
      ],
      "metadata": {
        "id": "zVJGKHYVF2U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **Observation:**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### We observe that none of the transformations are making our target variable perfectly normal, but still log trasnformation is giving better results than others. So we will be applying log transformation on the target variable.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ryfsl-8xoLck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the log transformation on target variable\n",
        "energy_df = energy_df.copy()\n",
        "energy_df['Log_Appliances'] = np.log(energy_df['Appliances'])"
      ],
      "metadata": {
        "id": "6vt-zPk9oHGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "energy_df"
      ],
      "metadata": {
        "id": "E6ihdmSBuTxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Appliance usage distribution before and after log transformation.\n",
        "fig, ax = plt.subplots(1,2, figsize=(16,6))\n",
        "sns.histplot(x='Appliances', data=energy_df, binwidth=20, ax=ax[0],kde=True,color='blue')\n",
        "sns.histplot(x='Log_Appliances', data=energy_df, binwidth=0.09, ax=ax[1],kde=True,color='blue')\n",
        "ax[0].set_title('Appliance Usage Distribution Before Log Transformation')\n",
        "ax[1].set_title('Appliance Usage Distribution After Log Transformation')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LyDjorjY5x9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the distribution of the lights feature\n",
        "energy_df.lights.hist(bins=8)\n",
        "plt.title(\"Distribution of Lights feature\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-vgxxQLhJ2lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the value count of the lights features\n",
        "energy_df.lights.value_counts()"
      ],
      "metadata": {
        "id": "HizQY6XfKgFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Since most of the value in lights column is 0, it wont be playing much role in our model. Hence we drop the lights feature from our dataframe.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "jR-a8uTVKdTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the column lights\n",
        "energy_df = energy_df.drop('lights', axis=1)"
      ],
      "metadata": {
        "id": "I2bLaoHaJ2n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting date feature from object type to datetime feature and extracting the month, weekday, hour\n",
        "energy_df['weekday'] = ((pd.to_datetime(energy_df['date']).dt.dayofweek)// 5 == 0).astype(int)\n",
        "energy_df['hour'] = pd.to_datetime(energy_df['date']).dt.hour\n",
        "energy_df['month'] = pd.to_datetime(energy_df['date']).dt.month"
      ],
      "metadata": {
        "id": "xe9o1KwIJ2p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the Appliances energy consumption per hours of the day\n",
        "fig, ax = plt.subplots(1,1,figsize=(18,10))\n",
        "energy_df.groupby('hour').agg({'Appliances' : 'mean'}).plot.bar(ax=ax)\n",
        "plt.title(\"Hours of Day vs Appliances energy consumption\")\n",
        "ax.set_xlabel(\"Hours of the day\")\n",
        "ax.set_ylabel('Appliance energy (Wh)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GmewaV7aJ2sU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **Observations**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Above figure is a representation of average energy consumption of appliances at different time of the day over a period of 4.5 months. We observe two peak hours. One at 11 am in the morning and other at 6 PM in the evening. While the peak at 11 am is shallow and low, peak at 6 PM is comparatively higher and sharper.\n",
        "\n",
        "### We observe that over the sleeping hours (10 PM - 6 AM) the energy consumption of appliances is around 50 Wh. After about 6 AM, energy consumption starts to rise gradually up until 11 AM (probably due to morning chores). And then gradually decreases to around 100 Wh at about 3 PM. After which the energy consumption drastically shoots up up until 6 PM in the evening (probably due to requirement lights in rooms). However energy consumption of appliances reverts back to 50 Wh, as night approaches and people in the house go to bed at around 10 PM.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "IC33DtDSMWqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing appliances energy consumption on weekday and weekends\n",
        "fig, ax = plt.subplots(1,2,figsize=(18,9))\n",
        "week_df = energy_df.groupby(['weekday','hour']).agg({'Appliances':'mean'}).reset_index(0)\n",
        "week_df[week_df.weekday==0].Appliances.plot.bar(ax=ax[0], label='weekends')\n",
        "week_df[week_df.weekday==1].Appliances.plot.bar(ax=ax[1], label='weekdays')\n",
        "ax[0].legend(loc='best')\n",
        "ax[1].legend(loc='best')\n",
        "ax[0].set_ylabel('Appliance Energy (Wh)')\n",
        "ax[1].set_ylabel('Appliance Energy (Wh)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bdy-Saj6J2uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Observation:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### We observe that the energy consumption of appliances during the office hours (8 AM - 4 PM) is higher in weekends compared to the weekdays. Also, average overall consumption is higher in weekends is pretty high.\n",
        "\n",
        "### Lets look at how temperature and humidity levels vary inside different rooms !\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2_vZlHOHOwHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the appliances energy consumption per hour per month\n",
        "fig, ax = plt.subplots(1,1,figsize=(25,5))\n",
        "energy_df.groupby(['month','hour']).agg({'Appliances' : 'mean'}).plot.bar(ax=ax)\n",
        "ax.set_ylabel('Appliance enrergy (Wh)')\n",
        "plt.title(\"Appliances Energy Consumption per Hours per Month\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wjpu3J7jJ25N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A trend of high consumption hours for each month seems to be similar to the over all trend.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "XHpV_puI4_1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the \n",
        "fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
        "week_df = energy_df.groupby(['weekday','hour']).agg({'Appliances':'mean'}).reset_index(0)\n",
        "week_df[week_df.weekday==0].Appliances.plot.bar(ax=ax[0], label='weekends')\n",
        "week_df[week_df.weekday==1].Appliances.plot.bar(ax=ax[1], label='weekdays')\n",
        "ax[0].legend(loc='best')\n",
        "ax[1].legend(loc='best')\n",
        "ax[0].set_ylabel('Appliance Energy (Wh)')\n",
        "ax[1].set_ylabel('Appliance Energy (Wh)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dff-BRo4DS9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **Observation**:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### We observe that the energy consumption of appliances during the office hours (8 AM - 4 PM) is higher in weekends compared to the weekdays. Also, average overall consumption is higher in weekends is pretty high.\n",
        "\n",
        "### Lets look at how temperature and humidity levels vary inside different rooms !\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zmMC8BVe--TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the temperature level for each kind of rooms on an hourly basis\n",
        "fig, axes = plt.subplots(2,5,figsize=(40,16))\n",
        "for i, temp in enumerate(temp_dict.values()):\n",
        "  energy_df.groupby('hour').agg({temp : 'mean'}).plot.bar(ax=axes[i//5, i%5])\n",
        "  axes[i//5, i%5].legend(loc='best')\n",
        "  axes[i//5, i%5].set_title(temp)"
      ],
      "metadata": {
        "id": "l7TxfMDcDTAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Observations:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* ### The average temperature inside each of the rooms has been almost constant over the day. \n",
        "* ### However the average temperature outside the building and near the station changes over the course of the day. \n",
        "* ### The average night time temperature is around 6 degree C, while average day time temperature varies over hours and peaks to 12 degree C at about 2-3 PM in the afternoon.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_KeivNMG_gSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the trend of temperature over the course of 4.5 months\n",
        "fig, axes = plt.subplots(2,5,figsize=(40,16))\n",
        "for i, temp in enumerate(temp_dict.values()):\n",
        "  energy_df.groupby('month').agg({temp : 'mean'}).plot.bar(ax=axes[i//5, i%5])\n",
        "  axes[i//5, i%5].legend(loc='best')\n",
        "  axes[i//5, i%5].set_title(temp)"
      ],
      "metadata": {
        "id": "sIye7bfMDTwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **Observations:**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* ### We observe a significant increasing trend of daytime outside temperatures over the course of 5 months starting from an avg of 4 degree celsius in 1st month to an average of 15 degree celsius in month 5. \n",
        "\n",
        "* ### The outside temperatures seem to have an impact over temperature inside too, although the variance of temperatures inside the building is low, since the temperature inside is controlled. Although the increase temperature seem to have no impact on the appliance consumtion patterns.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "e9IcTq2EAOgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Observing the humidity level of each hour a day\n",
        "fig, axes = plt.subplots(2,5,figsize=(40,16))\n",
        "for i, humid in enumerate(humid_dict.values()):\n",
        "  energy_df.groupby('hour').agg({humid : 'mean'}).plot.bar(ax=axes[i//5, i%5])\n",
        "  axes[i//5, i%5].legend(loc='best')\n",
        "  axes[i//5, i%5].set_title(humid)"
      ],
      "metadata": {
        "id": "l8VjFJhdDT8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observing the humidity level over the course of 4.5 months\n",
        "fig, axes = plt.subplots(2,5,figsize=(40,16))\n",
        "for i, humid in enumerate(humid_dict.values()):\n",
        "  energy_df.groupby('month').agg({humid : 'mean'}).plot.bar(ax=axes[i//5, i%5])\n",
        "  axes[i//5, i%5].legend(loc='best')\n",
        "  axes[i//5, i%5].set_title(humid)"
      ],
      "metadata": {
        "id": "0sfEKwvrDUFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ### Although the humidity outside building tend to decrease over months, the humidity inside rooms seem to be unaffected. The humidity levels outside seem to be negatively correlated to with the temperature levels outside. Lets check !"
      ],
      "metadata": {
        "id": "KPSjcn6BB_k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "energy_df[['temp_outside', 'humid_outside']].corr()"
      ],
      "metadata": {
        "id": "zo1pYJQADUPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ### Indeed there is a strong negative correlation between temperature and humidity levels outside. As temperature increases, moisture levels in the air decreases. We also observe that during the day time when the temperatures are high, humidity levels are low."
      ],
      "metadata": {
        "id": "yYFBktiY_T_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the correlation between features and target variable\n",
        "cols = list(temp_dict.values())\n",
        "cols.extend(list(humid_dict.values()))\n",
        "cols.extend(['Appliances'])\n",
        "fig, ax = plt.subplots(1,1,figsize=(15,10))\n",
        "sns.heatmap(energy_df[cols].corr(),ax=ax, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xSpYveg7PKZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Observations :\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "* ### From the correlation graph we clearly observe that the features related to temperature and features related to humidity have positive correlation within themselves whereas have a a very little to no correlation with each other.\n",
        "\n",
        "* ### Humidity outside have a strong negative correlation with temperature levels as already discussed.\n",
        "\n",
        "\n",
        "* ### Apart from that we observe that a couple features such as humidity at station, temperature outside the building and temperature in the living room have a comparatively high absolute correlation (above 0.12) with Appliances energy consumption.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zISLSWAWPh57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let us plot the variation of energy consumption with these variables\n",
        "fig, axes = plt.subplots(4,5,figsize = (50,40))\n",
        "for i, col in enumerate(cols[:-1]):\n",
        "  ax = axes[i//5, i%5]\n",
        "  ax.scatter(energy_df[col], energy_df['Appliances'])\n",
        "  ax.set_xlabel(col)\n",
        "  ax.set_ylabel('Appliances')"
      ],
      "metadata": {
        "id": "77G5dWLmPgtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lets look at the dependence of appliance energy consumption on newly created variables!**"
      ],
      "metadata": {
        "id": "aKZF8XERyvDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the correlation between target variable and newly created variables.\n",
        "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
        "sns.heatmap(energy_df[['month', 'weekday', 'hour', 'Appliances']].corr(), annot=True, ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6uo0CkmQykK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Observations**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* ### As we have observed earlier as well, there seenms to be no correlation between month and the observed energy use i.e. the enegy consumption pretty much remains similar over all months. \n",
        "\n",
        "* ### Similarly there is no direct effect of weekdays on appliance energy consumption.\n",
        "\n",
        "* ### Although there is a correlation of 0.22 between hour and appliances.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yBnOpGevzHZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing a simple function to create a new feature called session\n",
        "def create_session(x):\n",
        "  if x <= 6 or x >= 22:\n",
        "    return 1\n",
        "  elif x>6 and x <=15:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3"
      ],
      "metadata": {
        "id": "Dy5QuQRmy_n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets create a new column based on our observations\n",
        "energy_df['session'] = energy_df['hour'].apply(lambda x : create_session(x))"
      ],
      "metadata": {
        "id": "rlX84XuVzy-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's plot a correlation plot\n",
        "fig,ax = plt.subplots(1,1,figsize=(10,8))\n",
        "sns.heatmap(energy_df[['session', 'Appliances']].corr(), ax = ax, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_8NaGQzPz10W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the appliances energy usages cross session\n",
        "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
        "sns.boxplot(x='session',y='Appliances',data=energy_df, ax = ax)\n",
        "plt.title(\"Appliances energy consumption across different session\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZMBW8d1_z-UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We were now able to increase the correlation to 0.34 by making creating this new row. We see a clear distinction of power consumtion in different sessions.\n",
        "\n",
        "## Lets look at features related to weather as well."
      ],
      "metadata": {
        "id": "aToMMDTf0msn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Again rechecking the correlation between features and target variable\n",
        "fig,ax = plt.subplots(1,1,figsize=(20,15))\n",
        "sns.heatmap(energy_df[weather_cols + cols].corr(), ax = ax, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BCIc_acp0IJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#**Observations**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Tdewpoint shows a high correlation with most of the tempearture and humidity level features than any other weather parameters. Pressure, windspeed and visibiltiy show little to no correlation. We might need to include only these feaatures in our final model\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Lets now deep dive into reducing the temperature and humidity parameters through some feature engineering and come up with features that explain maximum variability."
      ],
      "metadata": {
        "id": "kgZPC7yi35x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the correlation between target variable and temperature features\n",
        "temp_cols = list(set(list(temp_dict.values())) - {'temp_outside', 'temp_station'})\n",
        "energy_df['mean_temp'] = energy_df[temp_cols].mean(axis=1)\n",
        "energy_df[['mean_temp', 'Appliances']].corr()"
      ],
      "metadata": {
        "id": "v2uNQ_pu00zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Observations**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Since most of the temperature variables inside the room show little to know correlation with target variable, lets try to find components that could explain maximum variance, which might improve the correlation with target variable as well.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### Before doing PCA, I need to split the data into train and test, and fit PCA on train set"
      ],
      "metadata": {
        "id": "h-Rym5Nb5C9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a train test split for PCA\n",
        "train_energy_df, test_energy_df = train_test_split(energy_df, test_size=0.2, random_state=1)"
      ],
      "metadata": {
        "id": "ZjnfbdJc4Uac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting PCA \n",
        "pca = PCA()\n",
        "pca.fit(train_energy_df[temp_cols])\n",
        "temp_pca = pca.transform(energy_df[temp_cols])\n",
        "variance = pca.explained_variance_ratio_*100\n",
        "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
        "ax.bar(range(len(variance)), variance)\n",
        "ax.plot(range(len(variance)), np.cumsum(variance),'r.-',linewidth=2, label='Cummulative variance %')\n",
        "ax.set_xlabel('Principal components')\n",
        "ax.set_ylabel('Explained variance %')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qlCEaWQ25dj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the variance\n",
        "variance"
      ],
      "metadata": {
        "id": "oQuMLnP05jiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First two components seem to explain more than 91 % of variance in data."
      ],
      "metadata": {
        "id": "v9Wfe9l_59ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding new features of PCA in dataframe\n",
        "for i in range(temp_pca.shape[1]):\n",
        "    energy_df[f'temp_pca{i+1}'] = temp_pca[:,i]"
      ],
      "metadata": {
        "id": "R2Dd9tjx6Kql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Observing the corrleation with PCA feature with target variable\n",
        "fig,ax = plt.subplots(1,1,figsize=(10,8))\n",
        "sns.heatmap(energy_df[['temp_pca1', 'temp_pca2', 'temp_pca3', 'temp_pca4','temp_pca5', 'temp_pca6', 'temp_pca7', 'temp_pca8', 'Appliances']].corr(), ax=ax,annot=True)\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "ONpijmUG6i8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets look at components of humid_pca4\n",
        "dict(zip(temp_cols, pca.components_[7,:]))"
      ],
      "metadata": {
        "id": "mBLP-4xy6zIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "humid_cols = list(set(list(humid_dict.values())) - {'humid_outside', 'humid_station'})\n",
        "energy_df['mean_humid'] = energy_df[humid_cols].mean(axis=1)\n",
        "energy_df[['mean_humid', 'Appliances']].corr()"
      ],
      "metadata": {
        "id": "Wp-egnOI7pFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing pca on Humid features\n",
        "pca = PCA()\n",
        "pca.fit(train_energy_df[humid_cols])\n",
        "humid_pca = pca.transform(energy_df[humid_cols])\n",
        "variance = pca.explained_variance_ratio_*100\n",
        "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
        "ax.bar(range(len(variance)), variance)\n",
        "ax.plot(range(len(variance)), np.cumsum(variance),'r.-',linewidth=2, label='Cummulative variance %')\n",
        "ax.set_xlabel('Principal components')\n",
        "ax.set_ylabel('Explained variance %')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OZySpHfztAYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Humid pca features to the dataframe\n",
        "for i in range(humid_pca.shape[1]):\n",
        "  energy_df[f'humid_pca{i+1}'] = humid_pca[:,i]"
      ],
      "metadata": {
        "id": "69PeO7Jnqz_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variance"
      ],
      "metadata": {
        "id": "y4yd8988tC43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observing the correlation with newly created humid pca with target variable\n",
        "fig,ax = plt.subplots(1,1,figsize=(10,8))\n",
        "sns.heatmap(energy_df[['humid_pca1', 'humid_pca2', 'humid_pca3', 'humid_pca4', 'humid_pca6', 'humid_pca7', 'humid_pca8', 'Log_Appliances']].corr(), ax = ax, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gLTgOtGntQgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(energy_df['humid_pca4'], energy_df['Appliances'])\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ziq2wHlGypW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets look at components of humid_pca4\n",
        "dict(zip(humid_cols, pca.components_[3,:]))"
      ],
      "metadata": {
        "id": "e5YGrreYVUAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the correlation between tempeature difference and target variable\n",
        "energy_df['diff_temp'] = energy_df['temp_outside'] - energy_df['mean_temp']\n",
        "energy_df[['diff_temp', 'Appliances']].corr()"
      ],
      "metadata": {
        "id": "8L-4MXquVkQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rechecking the log appliances\n",
        "energy_df['log_Appliances'] = np.log(energy_df['Appliances'])\n",
        "sns.histplot(energy_df.log_Appliances,bins=50,kde=True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "43YMsy5VVngw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling With PCA Features\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kdi3mH_fka1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finalizing features\n",
        "final_features = ['temp_pca1', 'temp_pca2', 'humid_pca1', 'humid_pca2', 'temp_outside', 'humid_outside', 'weekday', 'session', 'Windspeed', 'Press_mm_hg', 'log_Appliances']"
      ],
      "metadata": {
        "id": "_1xWkeNaV90_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the correalation with finalised features\n",
        "fig,ax = plt.subplots(1,1,figsize=(10,8))\n",
        "sns.heatmap(energy_df[final_features].corr(), ax = ax, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z3869sS-WbaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split\n",
        "final_train_df, final_test_df = train_test_split(energy_df[final_features], test_size = 0.2, random_state = 1)\n"
      ],
      "metadata": {
        "id": "y0XcG_sCWfb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "energy_df.head()"
      ],
      "metadata": {
        "id": "IqaURQ86lLEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X_train, X_test, Y_train, Y_test.\n",
        "X_train, y_train = final_train_df.drop(['log_Appliances'], axis=1), final_train_df['log_Appliances']\n",
        "X_test, y_test = final_test_df.drop(['log_Appliances'], axis=1), final_test_df['log_Appliances']"
      ],
      "metadata": {
        "id": "yifcFC9mkqtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization of features\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "metadata": {
        "id": "IL9hOBidlelf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# The ML regressor models that we use are :\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### Lasso Regressor\n",
        "\n",
        "### Ridge Regressor\n",
        "\n",
        "### KNeighbors Regressor\n",
        "\n",
        "### Support Vector Regressor\n",
        "\n",
        "### Random Forest Regressor\n",
        "\n",
        "### Extra Tree Regressor\n",
        "\n",
        "### Gradient Boosting Regressor\n",
        "\n",
        "### XGB Regressor\n",
        "\n",
        "### MLP Regressor"
      ],
      "metadata": {
        "id": "o35kq4QYmKCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models=[\n",
        "           ['Lasso: ', Lasso()],\n",
        "           ['Ridge: ', Ridge()],\n",
        "           ['KNeighborsRegressor: ',  neighbors.KNeighborsRegressor()],\n",
        "           ['SVR:' , SVR(kernel='rbf')],\n",
        "           ['RandomForest ',RandomForestRegressor()],\n",
        "           ['ExtraTreeRegressor :',ExtraTreesRegressor()],\n",
        "           ['GradientBoostingRegressor: ', GradientBoostingRegressor()] ,\n",
        "           ['XGBRegressor: ', xgb.XGBRegressor()] ,\n",
        "           ['MLPRegressor: ', MLPRegressor(  activation='relu', solver='adam',learning_rate='adaptive',max_iter=1000,learning_rate_init=0.01,alpha=0.01)]\n",
        "         ]"
      ],
      "metadata": {
        "id": "DgtvpfyumFb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of Models\n",
        "model_data = []\n",
        "for name,curr_model in models :\n",
        "    curr_model_data = {}\n",
        "    curr_model.random_state = 78\n",
        "    curr_model_data[\"Name\"] = name\n",
        "    start = time.time()\n",
        "    curr_model.fit(X_train,y_train)\n",
        "    end = time.time()\n",
        "    curr_model_data[\"Train_Time\"] = end - start\n",
        "    curr_model_data[\"Train_R2_Score\"] = r2_score(y_train,curr_model.predict(X_train))\n",
        "    curr_model_data[\"Test_R2_Score\"] = r2_score(y_test,curr_model.predict(X_test))\n",
        "    curr_model_data[\"Test_RMSE_Score\"] = np.sqrt(mean_squared_error(y_test,curr_model.predict(X_test)))\n",
        "    model_data.append(curr_model_data)"
      ],
      "metadata": {
        "id": "-ShQ8xVR4uU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing the results of each model into a dataframe\n",
        "results_df = df = pd.DataFrame(model_data)"
      ],
      "metadata": {
        "id": "0EY9uh7F41ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df\n"
      ],
      "metadata": {
        "id": "nZ0IrDfu41bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of each model\n",
        "results_df.plot.bar(x=\"Name\", y=['Test_R2_Score' , 'Train_R2_Score' , 'Test_RMSE_Score'], title = 'Results' , width = .6, figsize= (20,8))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZxTeDQSR41fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# OBSERVATIONS :\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "* ### Extra Tree Regressor performs the best so far with a R2 score of 0.59 and RMSE of 0.65.\n",
        "* ### Lasso regression is the worst performing model so far.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yN5e9lL16_qQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper-parameter Tuning"
      ],
      "metadata": {
        "id": "Dd3vvHlDnL7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameter Tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = [{\n",
        "              'max_depth': [80, 150, 200,250],\n",
        "              'n_estimators' : [100,150,200,250],\n",
        "              'max_features': [\"auto\", \"sqrt\", \"log2\"]\n",
        "            }]\n",
        "reg = ExtraTreesRegressor(random_state=40)\n",
        "grid_search = GridSearchCV(estimator = reg, param_grid = param_grid, cv = 5, n_jobs = -1 , scoring='r2' , verbose=2)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ClVyJaXl6-CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "8RLQ9jQK6zAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "QYumkzqYQWBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_estimator_.score(X_train,y_train)"
      ],
      "metadata": {
        "id": "MYdiSZy8Qbck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_estimator_.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "sEVi-lJQQbgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(mean_squared_error(y_test, grid_search.best_estimator_.predict(X_test)))"
      ],
      "metadata": {
        "id": "oc5Bo8t9QbkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = pd.DataFrame(X_test, columns=final_features[:-1])\n",
        "y_test = pd.Series(y_test, name = 'Appliances')"
      ],
      "metadata": {
        "id": "nwLBBfusQbyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session_errors = []\n",
        "for i in range(1,4):\n",
        "  session_errors.append(np.sqrt(mean_squared_error(y_test[X_test.session*sc_X.scale_[-3] + sc_X.mean_[-3] == i]*sc_y.scale_ + sc_y.mean_, \n",
        "                                                   grid_search.best_estimator_.predict(X_test[X_test.session*sc_X.scale_[-3] + sc_X.mean_[-3] == i])*sc_y.scale_ + sc_y.mean_)))"
      ],
      "metadata": {
        "id": "roSF14F0Qb2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(x=['10 PM - 6 AM', '6 AM - 3 PM', '3 PM - 10 PM'], height=session_errors, width = 0.5)\n",
        "plt.axhline(np.sqrt(mean_squared_error(y_test*sc_y.scale_ + sc_y.mean_, \n",
        "                                       grid_search.best_estimator_.predict(X_test)*sc_y.scale_ + sc_y.mean_)), \n",
        "            color='red', label='average RMSE')\n",
        "plt.xlabel('Appliances Energy (Wh)')\n",
        "plt.ylabel('RMSE')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zM3WKOGwSDvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Observations:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### When we look at the root mean squared errors made in prediction of energy consumption in appliances at different time of the day, we observe that errors made are quite less than the average RMSE of entire test set. Which is quite intuitive since we had little to no variance in energy consumption in those hours. However the errors are above average for other two time frames, where we had seen a quite a variance in energy levels.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rpIh98fySMF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1,1,figsize=(20,5))\n",
        "plt.plot(range(len(y_test[:200])), y_test[:200]*sc_y.scale_ + sc_y.mean_, label='actual')\n",
        "plt.plot(range(len(y_test[:200])), grid_search.best_estimator_.predict(X_test.iloc[:200,:])*sc_y.scale_ + sc_y.mean_, label='predicted')\n",
        "plt.legend(loc='best')\n",
        "plt.ylabel('Appliance energy consumption (Wh)')\n",
        "plt.xlabel('Samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZvnHTGPiSD-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_indices = np.argsort(grid_search.best_estimator_.feature_importances_)\n",
        "importances = grid_search.best_estimator_.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "names = [final_train_df.columns[i] for i in indices]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.bar(range(X_train.shape[1]), importances[indices])\n",
        "plt.xticks(range(X_train.shape[1]), names, rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q-gEa9IKSEEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling Without PCA features:\n",
        "### Including all temperature and humidity features and engineered feature 'session' in our features set."
      ],
      "metadata": {
        "id": "rVnaxSZuk8DQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_features = ['temp_laundry','temp_bath', 'temp_kitchen', 'temp_parents', 'temp_office', 'temp_living', 'temp_teen', 'temp_iron','humid_kitchen',\n",
        " 'humid_office', 'humid_bath', 'humid_living', 'humid_parents', 'humid_laundry', 'humid_teen', 'humid_iron',\n",
        "  'temp_outside', 'humid_outside', 'temp_station', 'humid_station', 'weekday', 'session', 'Windspeed', 'Press_mm_hg', 'Appliances']"
      ],
      "metadata": {
        "id": "Z7fKG-5plJSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_train_df, final_test_df = train_test_split(energy_df[final_features], test_size = 0.2, random_state = 1)"
      ],
      "metadata": {
        "id": "liqH2vtNlJVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = final_train_df.drop('Appliances', axis=1), final_train_df['Appliances']\n",
        "X_test, y_test = final_test_df.drop('Appliances', axis=1), final_test_df['Appliances']"
      ],
      "metadata": {
        "id": "Vjb_FrKglJYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "metadata": {
        "id": "_cjKmQG0lJbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc_y = StandardScaler()\n",
        "y_train = sc_y.fit_transform(y_train.values.reshape([-1,1])).flatten()\n",
        "y_test = sc_y.transform(y_test.values.reshape([-1,1])).flatten()"
      ],
      "metadata": {
        "id": "tIZz05V-Yzkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "           ['Lasso: ', Lasso()],\n",
        "           ['Ridge: ', Ridge()],\n",
        "           ['KNeighborsRegressor: ',  neighbors.KNeighborsRegressor()],\n",
        "           ['SVR:' , SVR(kernel='rbf')],\n",
        "           ['RandomForest ',RandomForestRegressor()],\n",
        "           ['ExtraTreeRegressor :',ExtraTreesRegressor()],\n",
        "           ['GradientBoostingRegressor: ', GradientBoostingRegressor()],\n",
        "           ['XGBRegressor: ', xgb.XGBRegressor()],\n",
        "           ['MLPRegressor: ', MLPRegressor(  activation='relu', solver='adam',learning_rate='adaptive',max_iter=1000,learning_rate_init=0.01,alpha=0.01)]\n",
        "         ]"
      ],
      "metadata": {
        "id": "CeKHWVoYlJho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_data = []\n",
        "for name,curr_model in models :\n",
        "    curr_model_data = {}\n",
        "    curr_model.random_state = 78\n",
        "    curr_model_data[\"Name\"] = name\n",
        "    start = time.time()\n",
        "    curr_model.fit(X_train,y_train)\n",
        "    end = time.time()\n",
        "    curr_model_data[\"Train_Time\"] = end - start\n",
        "    curr_model_data[\"Train_R2_Score\"] = r2_score(y_train,curr_model.predict(X_train))\n",
        "    curr_model_data[\"Test_R2_Score\"] = r2_score(y_test,curr_model.predict(X_test))\n",
        "    curr_model_data[\"Test_RMSE_Score\"] = np.sqrt(mean_squared_error(y_test,curr_model.predict(X_test)))\n",
        "    model_data.append(curr_model_data)"
      ],
      "metadata": {
        "id": "BRTqPhQ3lJk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(model_data)\n"
      ],
      "metadata": {
        "id": "Lw8YnGU_lJoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df\n"
      ],
      "metadata": {
        "id": "Gnaybg6glfKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.plot.bar(x=\"Name\", y=['Test_R2_Score' , 'Train_R2_Score' , 'Test_RMSE_Score'], title = 'Results' , width = .6, figsize= (20,8))"
      ],
      "metadata": {
        "id": "drK6LRfslfNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vbDWqfvvaWIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper-parameter Tuning"
      ],
      "metadata": {
        "id": "M_kObNGui9Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = [{\n",
        "              'max_depth': [80, 150, 200,250],\n",
        "              'n_estimators' : [100,150,200,250],\n",
        "              'max_features': [\"auto\", \"sqrt\", \"log2\"]\n",
        "            }]\n",
        "reg = ExtraTreesRegressor(random_state=40)\n",
        "grid_search = GridSearchCV(estimator = reg, param_grid = param_grid, cv = 5, n_jobs = -1 , scoring='r2' , verbose=2)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "aF-7zR36jAWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "ryghbU98jAaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "jF1hjwWMjAeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_estimator_.score(X_train,y_train)"
      ],
      "metadata": {
        "id": "-V11TLVwjAi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_estimator_.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "ts-24pOZjAmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(mean_squared_error(y_test, grid_search.best_estimator_.predict(X_test)))"
      ],
      "metadata": {
        "id": "_mZuhG0mjOIz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}